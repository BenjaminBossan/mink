{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with linear networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mink's *layers* work exactly as sklearn *transformers*, and linear networks work analogously to sklearn Pipelines.\n",
    "\n",
    "To get a pipeline in mink, instead of using sklearn's `make_pipeline` with estimators and transformers, use mink's `make_network` with mink layers. Alternatively, define a network by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mink import layers\n",
    "from mink import nonlinearities\n",
    "from mink import objectives\n",
    "from mink import updates\n",
    "from mink import make_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn toy classification data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_classes=5,\n",
    "    n_informative=10,\n",
    "    random_state=0,\n",
    ")\n",
    "y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare network with `make_network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple linear network with an input layer, a hidden layer, and an output layer, by passing a list of these layers to `make_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_lst = [\n",
    "    layers.InputLayer(),\n",
    "    layers.DenseLayer(),\n",
    "    layers.DenseLayer(\n",
    "        num_units=5,\n",
    "        nonlinearity=nonlinearities.Softmax(),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = make_network(layer_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get symbolic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs = tf.placeholder(dtype='float32', shape=(None, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = tf.placeholder(dtype='float32', shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in sklearn, we can call `fit_transform` and the pipeline to get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys_out = network.fit_transform(Xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = objectives.CrossEntropy()(ys, ys_out)\n",
    "train_step = updates.Momentum()(loss)\n",
    "inputs = [train_step, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3625\n",
      "Loss: 0.9353\n",
      "Loss: 0.8366\n",
      "Loss: 0.7714\n",
      "Loss: 0.7194\n",
      "Loss: 0.6756\n",
      "Loss: 0.6371\n",
      "Loss: 0.6030\n",
      "Loss: 0.5730\n",
      "Loss: 0.5455\n",
      "Loss: 0.5204\n",
      "Loss: 0.4980\n",
      "Loss: 0.4777\n",
      "Loss: 0.4597\n",
      "Loss: 0.4428\n",
      "Loss: 0.4278\n",
      "Loss: 0.4135\n",
      "Loss: 0.4010\n",
      "Loss: 0.3889\n",
      "Loss: 0.3780\n",
      "Loss: 0.3674\n",
      "Loss: 0.3572\n",
      "Loss: 0.3481\n",
      "Loss: 0.3389\n",
      "Loss: 0.3307\n",
      "Loss: 0.3232\n",
      "Loss: 0.3155\n",
      "Loss: 0.3081\n",
      "Loss: 0.3016\n",
      "Loss: 0.2951\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "losses = []\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    for epoch in range(30):\n",
    "        losses_epoch = []\n",
    "        for i in range((X.shape[0] + batch_size - 1) // batch_size):\n",
    "            Xb = X[i * batch_size:(i + 1) * batch_size]\n",
    "            yb = y[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            feed_dict = {Xs: Xb, ys: yb}\n",
    "            _, loss = session.run(inputs, feed_dict=feed_dict)\n",
    "            losses_epoch.append(loss)\n",
    "        losses_mean = np.mean(losses_epoch)\n",
    "        losses.append(losses_mean)\n",
    "        print(\"Loss: {:.4f}\".format(losses_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare network by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can feedforward the output of each layer and pass the output to the next layer by hand. This will result in exactly the same network as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = layers.InputLayer(Xs, ys).fit_transform(Xs)\n",
    "out = layers.DenseLayer().fit_transform(out)\n",
    "out = layers.DenseLayer(num_units=5, nonlinearity=nonlinearities.Softmax()).fit_transform(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = objectives.CrossEntropy()(ys, out)\n",
    "train_step = updates.Momentum()(loss)\n",
    "inputs = [train_step, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4079\n",
      "Loss: 0.9245\n",
      "Loss: 0.8336\n",
      "Loss: 0.7704\n",
      "Loss: 0.7192\n",
      "Loss: 0.6755\n",
      "Loss: 0.6367\n",
      "Loss: 0.6030\n",
      "Loss: 0.5731\n",
      "Loss: 0.5461\n",
      "Loss: 0.5218\n",
      "Loss: 0.4997\n",
      "Loss: 0.4801\n",
      "Loss: 0.4622\n",
      "Loss: 0.4456\n",
      "Loss: 0.4304\n",
      "Loss: 0.4168\n",
      "Loss: 0.4040\n",
      "Loss: 0.3920\n",
      "Loss: 0.3812\n",
      "Loss: 0.3702\n",
      "Loss: 0.3608\n",
      "Loss: 0.3514\n",
      "Loss: 0.3424\n",
      "Loss: 0.3342\n",
      "Loss: 0.3262\n",
      "Loss: 0.3185\n",
      "Loss: 0.3115\n",
      "Loss: 0.3049\n",
      "Loss: 0.2982\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "losses = []\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    for epoch in range(30):\n",
    "        losses_epoch = []\n",
    "        for i in range((X.shape[0] + batch_size - 1) // batch_size):\n",
    "            Xb = X[i * batch_size:(i + 1) * batch_size]\n",
    "            yb = y[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            feed_dict = {Xs: Xb, ys: yb}\n",
    "            _, loss = session.run(inputs, feed_dict=feed_dict)\n",
    "            losses_epoch.append(loss)\n",
    "        losses_mean = np.mean(losses_epoch)\n",
    "        losses.append(losses_mean)\n",
    "        print(\"Loss: {:.4f}\".format(losses_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
