{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mink usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates some examples of using mink and how it interacts with sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mink import NeuralNetClassifier\n",
    "from mink import NeuralNetRegressor\n",
    "from mink.layers import DenseLayer\n",
    "from mink.layers import InputLayer\n",
    "from mink.updates import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: No need to specify the shape of the training data, number of classes, or to set softmax nonlinearity. The `NeuralNetClassifier` class takes care of all of that, as is expected from an sklearn estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0 = InputLayer()\n",
    "l1 = DenseLayer(l0, num_units=200)\n",
    "l2 = DenseLayer(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(l2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to change certain parameters after initialization, just use the `set_params` method and the double-underscore notation known from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetClassifier(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False),\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=InputLayer(Xs=None, make_logs=False, name=None, ys=None),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=200),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=None),\n",
       "          max_epochs=10, objective=CrossEntropy(eps=1e-12),\n",
       "          on_epoch_finished=(<mink.handlers.PrintTrainProgress object at 0x7f9ab017a400>,),\n",
       "          on_training_started=(<mink.handlers.PrintLayerInfo object at 0x7f9ab01c9a20>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.5), verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.set_params(update__learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 4602 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "|   # | name   |   size |\n",
      "|----:|:-------|-------:|\n",
      "|   0 | input  |     20 |\n",
      "|   1 | dense  |    200 |\n",
      "|   2 | dense  |      2 |\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetClassifier(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False),\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=InputLayer(Xs=None, make_logs=False, name=None, ys=None),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=200),\n",
       "      make_logs=False, name=None, nonlinearity=Softmax(), num_units=2),\n",
       "          max_epochs=10, objective=CrossEntropy(eps=1e-12),\n",
       "          on_epoch_finished=(<mink.handlers.PrintTrainProgress object at 0x7f9ab017a400>,),\n",
       "          on_training_started=(<mink.handlers.PrintLayerInfo object at 0x7f9ab01c9a20>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.5), verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y, num_epochs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48199999999999998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(y_proba, 1) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 4602 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "|   # | name   |   size |\n",
      "|----:|:-------|-------:|\n",
      "|   0 | input  |     20 |\n",
      "|   1 | dense  |    200 |\n",
      "|   2 | dense  |      2 |\n",
      "\n",
      "|   epoch |   train loss |     dur |\n",
      "|--------:|-------------:|--------:|\n",
      "|       0 |      \u001b[36m0.20988\u001b[0m | 0.04648 |\n",
      "|       1 |      \u001b[36m0.09319\u001b[0m | 0.03878 |\n",
      "|       2 |      \u001b[36m0.07161\u001b[0m | 0.03858 |\n",
      "|       3 |      \u001b[36m0.06325\u001b[0m | 0.03815 |\n",
      "|       4 |      \u001b[36m0.05884\u001b[0m | 0.03690 |\n",
      "|       5 |      \u001b[36m0.05591\u001b[0m | 0.03786 |\n",
      "|       6 |      \u001b[36m0.05368\u001b[0m | 0.03741 |\n",
      "|       7 |      \u001b[36m0.05181\u001b[0m | 0.03900 |\n",
      "|       8 |      \u001b[36m0.05018\u001b[0m | 0.03766 |\n",
      "|       9 |      \u001b[36m0.04868\u001b[0m | 0.04036 |\n",
      "|      10 |      \u001b[36m0.04731\u001b[0m | 0.04240 |\n",
      "|      11 |      \u001b[36m0.04602\u001b[0m | 0.04241 |\n",
      "|      12 |      \u001b[36m0.04480\u001b[0m | 0.04307 |\n",
      "|      13 |      \u001b[36m0.04366\u001b[0m | 0.03870 |\n",
      "|      14 |      \u001b[36m0.04251\u001b[0m | 0.03771 |\n",
      "|      15 |      \u001b[36m0.04154\u001b[0m | 0.03590 |\n",
      "|      16 |      \u001b[36m0.04051\u001b[0m | 0.03740 |\n",
      "|      17 |      \u001b[36m0.03958\u001b[0m | 0.03648 |\n",
      "|      18 |      \u001b[36m0.03861\u001b[0m | 0.03590 |\n",
      "|      19 |      \u001b[36m0.03775\u001b[0m | 0.03569 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetClassifier(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False),\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=InputLayer(Xs=None, make_logs=False, name=None, ys=None),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=200),\n",
       "      make_logs=False, name=None, nonlinearity=Softmax(), num_units=2),\n",
       "          max_epochs=10, objective=CrossEntropy(eps=1e-12),\n",
       "          on_epoch_finished=(<mink.handlers.PrintTrainProgress object at 0x7f9ab017a400>,),\n",
       "          on_training_started=(<mink.handlers.PrintLayerInfo object at 0x7f9ab01c9a20>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.5), verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99280000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(y_proba, 1) == y.flatten()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net estimators can be used in conjunction with other sklearn features, such as `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0 = InputLayer()\n",
    "l1 = DenseLayer(l0, name='hidden')\n",
    "l2 = DenseLayer(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(l2, update=SGD())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are set using the known double-underscore notation, e.g.\n",
    "\n",
    "`'update__learning_rate': [0.1, 0.5]`.\n",
    "\n",
    "Note: Instead of having to write\n",
    "\n",
    "`'layer__incoming__num_units': [50, 100]`\n",
    "\n",
    "we can just write\n",
    "\n",
    "`'hidden__num_units': [50, 100]`\n",
    "\n",
    "because we have given the hidden layer a name, \"hidden\". This may safe a lot of writing and confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'update__learning_rate': [0.1, 0.5],\n",
    "    'max_epochs': [5, 10],\n",
    "    'hidden__num_units': [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = GridSearchCV(net, params, scoring='accuracy', refit=False, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=50, score=0.954409 -   0.3s\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=50, score=0.950210 -   0.3s\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=50, score=0.960384 -   0.4s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=50, score=0.975405 -   0.4s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=50, score=0.983803 -   0.5s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=50 ...\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=50, score=0.976591 -   0.5s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=50, score=0.967606 -   0.7s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=50, score=0.971806 -   0.7s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=50, score=0.966387 -   0.7s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=50, score=0.976005 -   0.8s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=50, score=0.988002 -   0.8s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=50 ..\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=50, score=0.980192 -   0.8s\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=100, score=0.958608 -   0.7s\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=100, score=0.963407 -   0.7s\n",
      "[CV] max_epochs=5, update__learning_rate=0.1, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.1, hidden__num_units=100, score=0.959784 -   0.8s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=100, score=0.977205 -   0.8s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=100, score=0.985603 -   0.9s\n",
      "[CV] max_epochs=5, update__learning_rate=0.5, hidden__num_units=100 ..\n",
      "[CV]  max_epochs=5, update__learning_rate=0.5, hidden__num_units=100, score=0.979592 -   1.0s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=100, score=0.964607 -   1.0s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=100, score=0.976605 -   1.1s\n",
      "[CV] max_epochs=10, update__learning_rate=0.1, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.1, hidden__num_units=100, score=0.970588 -   1.1s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=100, score=0.979604 -   1.1s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=100, score=0.987403 -   1.2s\n",
      "[CV] max_epochs=10, update__learning_rate=0.5, hidden__num_units=100 .\n",
      "[CV]  max_epochs=10, update__learning_rate=0.5, hidden__num_units=100, score=0.982593 -   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=NeuralNetClassifier(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False),\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=Fa...ject at 0x7f9ab01c9a20>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.01), verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_epochs': [5, 10], 'update__learning_rate': [0.1, 0.5], 'hidden__num_units': [50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'hidden__num_units': 100, 'max_epochs': 10, 'update__learning_rate': 0.5},\n",
       " 0.98319999999999996)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_, cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is known from sklearn, we have separate estimators for classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that apart from using `NeuralNetRegressor` instead of `NeuralNetClassifier`, everything is the same. No need to adjust output nonlinearity or objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0 = InputLayer()\n",
    "l1 = DenseLayer(l0, num_units=200)\n",
    "l2 = DenseLayer(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNetRegressor(l2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetRegressor(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=None,\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=InputLayer(Xs=None, make_logs=False, name=None, ys=None),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=200),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=None),\n",
       "          max_epochs=10, objective=MeanSquaredError(),\n",
       "          on_epoch_finished=(<mink.handlers.PrintTrainProgress object at 0x7f9ab017a6a0>,),\n",
       "          on_training_started=(<mink.handlers.PrintLayerInfo object at 0x7f9ab017a668>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.0001), verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.set_params(update__learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 20401 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "|   # | name   |   size |\n",
      "|----:|:-------|-------:|\n",
      "|   0 | input  |    100 |\n",
      "|   1 | dense  |    200 |\n",
      "|   2 | dense  |      1 |\n",
      "\n",
      "|   epoch |   train loss |     dur |\n",
      "|--------:|-------------:|--------:|\n",
      "|       0 |  \u001b[36m25477.56836\u001b[0m | 0.06897 |\n",
      "|       1 |  \u001b[36m24711.97656\u001b[0m | 0.03186 |\n",
      "|       2 |  \u001b[36m22082.50391\u001b[0m | 0.03216 |\n",
      "|       3 |  \u001b[36m14621.14258\u001b[0m | 0.03380 |\n",
      "|       4 |   \u001b[36m4874.32520\u001b[0m | 0.03194 |\n",
      "|       5 |    \u001b[36m848.73694\u001b[0m | 0.02977 |\n",
      "|       6 |    \u001b[36m290.25079\u001b[0m | 0.02963 |\n",
      "|       7 |    \u001b[36m225.20493\u001b[0m | 0.03236 |\n",
      "|       8 |    \u001b[36m203.59399\u001b[0m | 0.03186 |\n",
      "|       9 |    \u001b[36m189.39383\u001b[0m | 0.03389 |\n",
      "|      10 |    \u001b[36m178.23537\u001b[0m | 0.03279 |\n",
      "|      11 |    \u001b[36m168.81763\u001b[0m | 0.03295 |\n",
      "|      12 |    \u001b[36m160.55678\u001b[0m | 0.03320 |\n",
      "|      13 |    \u001b[36m153.11763\u001b[0m | 0.03267 |\n",
      "|      14 |    \u001b[36m146.26237\u001b[0m | 0.03077 |\n",
      "|      15 |    \u001b[36m139.88733\u001b[0m | 0.03060 |\n",
      "|      16 |    \u001b[36m133.89516\u001b[0m | 0.03199 |\n",
      "|      17 |    \u001b[36m128.23994\u001b[0m | 0.03418 |\n",
      "|      18 |    \u001b[36m122.87547\u001b[0m | 0.03229 |\n",
      "|      19 |    \u001b[36m117.78522\u001b[0m | 0.03131 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetRegressor(batch_iterator_test=128, batch_iterator_train=128,\n",
       "          encoder=None,\n",
       "          layer=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=DenseLayer(W=GlorotUniform(c01b=False, gain=1.0), b=Constant(value=0.0),\n",
       "      incoming=InputLayer(Xs=None, make_logs=False, name=None, ys=None),\n",
       "      make_logs=False, name=None, nonlinearity=None, num_units=200),\n",
       "      make_logs=False, name=None, nonlinearity=Linear(), num_units=1),\n",
       "          max_epochs=10, objective=MeanSquaredError(),\n",
       "          on_epoch_finished=(<mink.handlers.PrintTrainProgress object at 0x7f9ab017a6a0>,),\n",
       "          on_training_started=(<mink.handlers.PrintLayerInfo object at 0x7f9ab017a668>,),\n",
       "          session_kwargs=None, update=SGD(learning_rate=0.0001), verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving and restoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save previous net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.248460207\n"
     ]
    }
   ],
   "source": [
    "score_before = mean_squared_error(y, net.predict(X))\n",
    "print(score_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('mynet.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new net with same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mynet.pkl', 'rb') as f:\n",
    "    new_net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.248460207\n"
     ]
    }
   ],
   "source": [
    "score_after = mean_squared_error(y, new_net.predict(X))\n",
    "print(score_after)\n",
    "assert np.isclose(score_before, score_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
